{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from neuralnetwork import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only if you need to install nltk.corpus and nltk.stem\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data set and parse independent lines\n",
    "fd = open(\"Assignment_2_data.txt\",\"r\")\n",
    "file_data = fd.read()\n",
    "lines = (file_data).splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Necessary objects\n",
    "ps = PorterStemmer()\n",
    "y_target_names = []\n",
    "x = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "unique_tokens = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasing input file into labels and features \n",
    "for i in range(len(lines)): \n",
    "    # Splitting based on white space and non alpha numberic characters\n",
    "    words_tokens = re.split('\\W+',lines[i])\n",
    "    words_tokens = list(filter(lambda temp: (temp != '' ),words_tokens)) \n",
    "    \n",
    "    # Removing stop word from the data\n",
    "    filtered_sentence = []\n",
    "    for w in words_tokens:\n",
    "        if w not in stop_words:\n",
    "        # Applying porter stemmer\n",
    "            stemmed_word = ps.stem(w).lower()\n",
    "            filtered_sentence.append(stemmed_word)\n",
    "\n",
    "\n",
    "    # Store pre processed data in x and y_target_names\n",
    "    y_target_names.append(filtered_sentence[0])\n",
    "    x.append(filtered_sentence[1:])\n",
    "    unique_tokens.update(filtered_sentence[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare variables for one hot encoding\n",
    "N = len(x)\n",
    "unique_tokens = list(unique_tokens)\n",
    "encoding_length = (len(unique_tokens))\n",
    "x_encoded = np.zeros( ( N , encoding_length) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary encoding of features and labels\n",
    "for i in range(N):\n",
    "    for j in x[i]:\n",
    "        ind = unique_tokens.index(j)\n",
    "        x_encoded[i][ind] = 1;\n",
    "        \n",
    "y_target = np.ones((N,1))\n",
    "for i in range(len(y_target_names)):\n",
    "    if(y_target_names[i] == \"ham\"):\n",
    "        y_target[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test error\n",
    "trainN = int(0.8*N)\n",
    "\n",
    "X_train = x_encoded[0:trainN]\n",
    "y_train = y_target[0:trainN]\n",
    "\n",
    "X_test = x_encoded[trainN:]\n",
    "y_test = y_target[trainN:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4459, 7375)\n",
      "(4459, 1)\n"
     ]
    }
   ],
   "source": [
    "N,M = X_train.shape\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tanh activation function without softmax layer 2A1\n",
    "nn = NeuralNetwork(M,np.array([100,50]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.train(X_train,y_train,X_test,y_test,epochs=500,learning_rate=1,learning_rate_decay=0.98,batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid without softmax layer 2A2\n",
    "nn2 = NeuralNetwork(M,np.array([100,50]),1,activation_function=\"sigmoid\",weight_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn2.train(X_train,y_train,X_test,y_test,epochs=500,learning_rate=2,learning_rate_decay=0.98,batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sigmoid activation function with softmax layer 2B1\n",
    "nn = NeuralNetwork(M,np.array([100,50]),2,activation_function=\"sigmoid\",weight_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Ratio of Correct predictions over testset(783/1115)-----------\n",
      "-----------Ratio of Correct predictions over training set(3127/4459)-----------\n",
      "Epoch (1/1000) Training Error : 0.148176\n",
      "Epoch (2/1000) Training Error : 0.130936\n",
      "Epoch (3/1000) Training Error : 0.128994\n",
      "Epoch (4/1000) Training Error : 0.127449\n",
      "Epoch (5/1000) Training Error : 0.125859\n",
      "Epoch (6/1000) Training Error : 0.124180\n",
      "Epoch (7/1000) Training Error : 0.122407\n",
      "Epoch (8/1000) Training Error : 0.120529\n",
      "Epoch (9/1000) Training Error : 0.118539\n",
      "Epoch (10/1000) Training Error : 0.116441\n",
      "Epoch (11/1000) Training Error : 0.114253\n",
      "Epoch (12/1000) Training Error : 0.111995\n",
      "Epoch (13/1000) Training Error : 0.109686\n",
      "Epoch (14/1000) Training Error : 0.107337\n",
      "Epoch (15/1000) Training Error : 0.104951\n",
      "Epoch (16/1000) Training Error : 0.102516\n",
      "Epoch (17/1000) Training Error : 0.100018\n",
      "Epoch (18/1000) Training Error : 0.097451\n",
      "Epoch (19/1000) Training Error : 0.094840\n",
      "Epoch (20/1000) Training Error : 0.092243\n",
      "Epoch (21/1000) Training Error : 0.089707\n",
      "Epoch (22/1000) Training Error : 0.087251\n",
      "Epoch (23/1000) Training Error : 0.084889\n",
      "Epoch (24/1000) Training Error : 0.082625\n",
      "Epoch (25/1000) Training Error : 0.080465\n",
      "-----------Ratio of Correct predictions over testset(991/1115)-----------\n",
      "-----------Ratio of Correct predictions over training set(4008/4459)-----------\n",
      "Epoch (26/1000) Training Error : 0.078423\n",
      "Epoch (27/1000) Training Error : 0.076489\n",
      "Epoch (28/1000) Training Error : 0.074653\n",
      "Epoch (29/1000) Training Error : 0.072920\n",
      "Epoch (30/1000) Training Error : 0.071286\n",
      "Epoch (31/1000) Training Error : 0.069745\n",
      "Epoch (32/1000) Training Error : 0.068287\n",
      "Epoch (33/1000) Training Error : 0.066902\n",
      "Epoch (34/1000) Training Error : 0.065578\n",
      "Epoch (35/1000) Training Error : 0.064309\n",
      "Epoch (36/1000) Training Error : 0.063088\n",
      "Epoch (37/1000) Training Error : 0.061909\n",
      "Epoch (38/1000) Training Error : 0.060770\n",
      "Epoch (39/1000) Training Error : 0.059670\n",
      "Epoch (40/1000) Training Error : 0.058608\n",
      "Epoch (41/1000) Training Error : 0.057585\n",
      "Epoch (42/1000) Training Error : 0.056603\n",
      "Epoch (43/1000) Training Error : 0.055661\n",
      "Epoch (44/1000) Training Error : 0.054759\n",
      "Epoch (45/1000) Training Error : 0.053897\n",
      "Epoch (46/1000) Training Error : 0.053073\n",
      "Epoch (47/1000) Training Error : 0.052283\n",
      "Epoch (48/1000) Training Error : 0.051526\n",
      "Epoch (49/1000) Training Error : 0.050801\n",
      "Epoch (50/1000) Training Error : 0.050105\n",
      "-----------Ratio of Correct predictions over testset(1013/1115)-----------\n",
      "-----------Ratio of Correct predictions over training set(4193/4459)-----------\n",
      "Epoch (51/1000) Training Error : 0.049449\n",
      "Epoch (52/1000) Training Error : 0.048816\n",
      "Epoch (53/1000) Training Error : 0.048205\n",
      "Epoch (54/1000) Training Error : 0.047616\n",
      "Epoch (55/1000) Training Error : 0.047047\n",
      "Epoch (56/1000) Training Error : 0.046496\n",
      "Epoch (57/1000) Training Error : 0.045963\n",
      "Epoch (58/1000) Training Error : 0.045447\n",
      "Epoch (59/1000) Training Error : 0.044946\n",
      "Epoch (60/1000) Training Error : 0.044460\n",
      "Epoch (61/1000) Training Error : 0.043987\n",
      "Epoch (62/1000) Training Error : 0.043526\n",
      "Epoch (63/1000) Training Error : 0.043077\n",
      "Epoch (64/1000) Training Error : 0.042638\n",
      "Epoch (65/1000) Training Error : 0.042209\n",
      "Epoch (66/1000) Training Error : 0.041789\n",
      "Epoch (67/1000) Training Error : 0.041377\n",
      "Epoch (68/1000) Training Error : 0.040972\n",
      "Epoch (69/1000) Training Error : 0.040573\n",
      "Epoch (70/1000) Training Error : 0.040180\n",
      "Epoch (71/1000) Training Error : 0.039792\n",
      "Epoch (72/1000) Training Error : 0.039408\n",
      "Epoch (73/1000) Training Error : 0.039027\n",
      "Epoch (74/1000) Training Error : 0.038650\n",
      "Epoch (75/1000) Training Error : 0.038274\n",
      "-----------Ratio of Correct predictions over testset(1027/1115)-----------\n",
      "-----------Ratio of Correct predictions over training set(4267/4459)-----------\n",
      "Epoch (76/1000) Training Error : 0.037907\n",
      "Epoch (77/1000) Training Error : 0.037540\n",
      "Epoch (78/1000) Training Error : 0.037173\n",
      "Epoch (79/1000) Training Error : 0.036806\n",
      "Epoch (80/1000) Training Error : 0.036438\n",
      "Epoch (81/1000) Training Error : 0.036070\n",
      "Epoch (82/1000) Training Error : 0.035702\n",
      "Epoch (83/1000) Training Error : 0.035336\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e8b889962158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.98\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"two\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Machine-Learning/assignment2/neuralnetwork.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, y_train, X_test, y_test, epochs, learning_rate, learning_rate_decay, batch_size, method)\u001b[0m\n\u001b[1;32m    228\u001b[0m                                 \u001b[0mtemp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"two\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                                         \u001b[0mtemp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                                         \u001b[0mtemp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Machine-Learning/assignment2/neuralnetwork.py\u001b[0m in \u001b[0;36mloss_2\u001b[0;34m(self, X, y_target, predict)\u001b[0m\n\u001b[1;32m    157\u001b[0m                                         \u001b[0mdX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexW\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexW\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Machine-Learning/assignment2/neuralnetwork.py\u001b[0m in \u001b[0;36mdlinear\u001b[0;34m(self, dX, W, X)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mdW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn.train(X_train,y_train,X_test,y_test,epochs=1000,learning_rate=2,learning_rate_decay=0.98,batch_size=1000,method=\"two\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tanh activation function with softmax layer 2B2\n",
    "nn2 = NeuralNetwork(M,np.array([100,50]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Ratio of Correct predictions over testset(217/1115)-----------\n",
      "-----------Ratio of Correct predictions over training set(945/4459)-----------\n",
      "Epoch (1/500) Training Error : 0.154407\n",
      "Epoch (2/500) Training Error : 0.099050\n",
      "Epoch (3/500) Training Error : 0.083068\n",
      "Epoch (4/500) Training Error : 0.065827\n",
      "Epoch (5/500) Training Error : 0.052627\n",
      "Epoch (6/500) Training Error : 0.043879\n",
      "Epoch (7/500) Training Error : 0.037901\n",
      "Epoch (8/500) Training Error : 0.033524\n",
      "Epoch (9/500) Training Error : 0.030116\n",
      "Epoch (10/500) Training Error : 0.027347\n",
      "Epoch (11/500) Training Error : 0.025038\n",
      "Epoch (12/500) Training Error : 0.023073\n",
      "Epoch (13/500) Training Error : 0.021368\n",
      "Epoch (14/500) Training Error : 0.019860\n",
      "Epoch (15/500) Training Error : 0.018517\n",
      "Epoch (16/500) Training Error : 0.017334\n",
      "Epoch (17/500) Training Error : 0.016297\n",
      "Epoch (18/500) Training Error : 0.015383\n",
      "Epoch (19/500) Training Error : 0.014567\n",
      "Epoch (20/500) Training Error : 0.013832\n",
      "Epoch (21/500) Training Error : 0.013161\n",
      "Epoch (22/500) Training Error : 0.012546\n",
      "Epoch (23/500) Training Error : 0.011978\n",
      "Epoch (24/500) Training Error : 0.011455\n",
      "Epoch (25/500) Training Error : 0.010974\n",
      "-----------Ratio of Correct predictions over testset(1091/1115)-----------\n",
      "-----------Ratio of Correct predictions over training set(4406/4459)-----------\n",
      "Epoch (26/500) Training Error : 0.010541\n",
      "Epoch (27/500) Training Error : 0.010141\n",
      "Epoch (28/500) Training Error : 0.009771\n",
      "Epoch (29/500) Training Error : 0.009428\n",
      "Epoch (30/500) Training Error : 0.009108\n",
      "Epoch (31/500) Training Error : 0.008811\n",
      "Epoch (32/500) Training Error : 0.008534\n",
      "Epoch (33/500) Training Error : 0.008275\n",
      "Epoch (34/500) Training Error : 0.008033\n",
      "Epoch (35/500) Training Error : 0.007806\n",
      "Epoch (36/500) Training Error : 0.007593\n",
      "Epoch (37/500) Training Error : 0.007392\n",
      "Epoch (38/500) Training Error : 0.007200\n",
      "Epoch (39/500) Training Error : 0.007017\n",
      "Epoch (40/500) Training Error : 0.006841\n",
      "Epoch (41/500) Training Error : 0.006669\n",
      "Epoch (42/500) Training Error : 0.006500\n",
      "Epoch (43/500) Training Error : 0.006333\n",
      "Epoch (44/500) Training Error : 0.006167\n",
      "Epoch (45/500) Training Error : 0.006004\n",
      "Epoch (46/500) Training Error : 0.005847\n",
      "Epoch (47/500) Training Error : 0.005702\n",
      "Epoch (48/500) Training Error : 0.005569\n",
      "Epoch (49/500) Training Error : 0.005447\n",
      "Epoch (50/500) Training Error : 0.005333\n",
      "-----------Ratio of Correct predictions over testset(1096/1115)-----------\n",
      "-----------Ratio of Correct predictions over training set(4436/4459)-----------\n",
      "Epoch (51/500) Training Error : 0.005228\n",
      "Epoch (52/500) Training Error : 0.005130\n",
      "Epoch (53/500) Training Error : 0.005038\n",
      "Epoch (54/500) Training Error : 0.004951\n",
      "Epoch (55/500) Training Error : 0.004871\n",
      "Epoch (56/500) Training Error : 0.004796\n",
      "Epoch (57/500) Training Error : 0.004726\n",
      "Epoch (58/500) Training Error : 0.004660\n",
      "Epoch (59/500) Training Error : 0.004596\n",
      "Epoch (60/500) Training Error : 0.004536\n",
      "Epoch (61/500) Training Error : 0.004477\n",
      "Epoch (62/500) Training Error : 0.004420\n",
      "Epoch (63/500) Training Error : 0.004365\n",
      "Epoch (64/500) Training Error : 0.004311\n",
      "Epoch (65/500) Training Error : 0.004258\n",
      "Epoch (66/500) Training Error : 0.004207\n",
      "Epoch (67/500) Training Error : 0.004157\n",
      "Epoch (68/500) Training Error : 0.004106\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-26211212a993>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.98\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"two\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Machine-Learning/assignment2/neuralnetwork.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, y_train, X_test, y_test, epochs, learning_rate, learning_rate_decay, batch_size, method)\u001b[0m\n\u001b[1;32m    228\u001b[0m                                 \u001b[0mtemp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"two\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                                         \u001b[0mtemp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                                         \u001b[0mtemp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Machine-Learning/assignment2/neuralnetwork.py\u001b[0m in \u001b[0;36mloss_2\u001b[0;34m(self, X, y_target, predict)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                         \u001b[0;31m# Affine function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                         \u001b[0mX_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                         \u001b[0;31m# Activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Machine-Learning/assignment2/neuralnetwork.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(self, X, W, b)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn2.train(X_train,y_train,X_test,y_test,epochs=500,learning_rate=1,learning_rate_decay=0.98,batch_size=1000,method=\"two\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
